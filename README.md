# ğŸ›¡ï¸ CyberWatch - AI-Powered Cybersecurity Intelligence Feed

CyberWatch est une application complÃ¨te de veille en cybersÃ©curitÃ©. Elle collecte automatiquement des articles, extrait les entitÃ©s clÃ©s (NER) grÃ¢ce au Machine Learning, et gÃ©nÃ¨re des synthÃ¨ses via une Intelligence Artificielle locale, le tout prÃ©sentÃ© sur un dashboard responsive et moderne.

## âœ¨ FonctionnalitÃ©s

* **Scraping AutomatisÃ© :** Collecte d'articles depuis diverses sources de Threat Intelligence.
* **Traitement NLP (spaCy) :** Extraction automatique d'entitÃ©s nommÃ©es (acteurs de la menace, malwares, CVE, etc.).
* **SynthÃ¨se par IA Locale (Ollama) :** RÃ©daction de rÃ©sumÃ©s clairs et formatÃ©s en Markdown.
* **Dashboard Responsive :** Interface front-end moderne (Tailwind CSS) optimisÃ©e pour bureau et mobile, avec traduction intÃ©grÃ©e.
* **100% ConteneurisÃ© :** DÃ©ploiement facile et isolÃ© via Docker.

## ğŸ› ï¸ Technologies UtilisÃ©es

* **Backend :** Python 3.11, FastAPI, LlamaIndex, spaCy, BeautifulSoup.
* **Frontend :** HTML5, Vanilla JavaScript, Tailwind CSS, Nginx.
* **IA & ModÃ¨les :** Ollama (LLM local), HuggingFace Embeddings.
* **Infrastructure :** Docker & Docker Compose.

---

## ğŸš€ Guide d'Installation

### 1. PrÃ©requis

**Pour Windows :**
* Docker Desktop (avec le backend WSL 2 activÃ©).
* Ollama pour Windows (tÃ©lÃ©chargeable sur ollama.com).
* Git.

**Pour Linux (Ubuntu/Debian) :**
* Docker Engine & Docker Compose.
* Ollama pour Linux (`curl -fsSL https://ollama.com/install.sh | sh`).
* Git.

### 2. Configuration de l'IA (Ollama)
L'application utilise un modÃ¨le local pour rÃ©diger les synthÃ¨ses. Ouvrez un terminal sur votre machine hÃ´te (pas dans Docker) et tÃ©lÃ©chargez le modÃ¨le lÃ©ger :

```bash
ollama pull llama3.2:1b
```
*(Assurez-vous qu'Ollama tourne en arriÃ¨re-plan).*

### 3. Cloner le projet

```bash
git clone [https://github.com/VOTRE_NOM/CyberWatch.git](https://github.com/VOTRE_NOM/CyberWatch.git)
cd CyberWatch
```

### 4. âš ï¸ Configuration SpÃ©cifique (Windows / Linux)

#### Allocation de la mÃ©moire (Windows uniquement)
Si vous Ãªtes sur Windows avec WSL 2, Docker a besoin de suffisamment de RAM pour faire tourner les modÃ¨les de Machine Learning (spaCy, Embeddings). 

1. CrÃ©ez un fichier `.wslconfig` dans votre dossier utilisateur (`C:\Users\VotreNom\.wslconfig`).
2. Ajoutez ceci pour allouer 8 Go de RAM (ajustez selon votre PC) :

```ini
[wsl2]
memory=8GB
```
3. RedÃ©marrez WSL en tapant `wsl --shutdown` dans votre terminal, puis relancez Docker Desktop.

#### Configuration du rÃ©seau (Windows & Linux)
Pour que l'application soit accessible depuis votre rÃ©seau local (ex: sur votre tÃ©lÃ©phone via le mÃªme Wi-Fi) :

1. Trouvez l'adresse IP locale de votre ordinateur (ex: `192.168.1.50`).
2. CrÃ©ez ou modifiez le fichier `frontend/config.js` et insÃ©rez votre IP :

```javascript
const CONFIG = {
    API_URL: "[http://192.168.](http://192.168.)X.X:8000" // Remplacez par votre vÃ©ritable adresse IP locale
};
```

### 5. Lancer l'application
Construisez et dÃ©marrez les conteneurs avec Docker Compose :

```bash
docker compose up --build -d
```
*(Note pour Windows : prÃ©fÃ©rez utiliser l'invite de commande standard `cmd` plutÃ´t que PowerShell si vous rencontrez des erreurs).*

---

## ğŸ“– Utilisation

Une fois les conteneurs dÃ©marrÃ©s, les services sont accessibles aux adresses suivantes :

* **Dashboard Web (Frontend) :** `http://localhost:8080` (ou `http://VOTRE_IP:8080` depuis un appareil mobile).
* **Documentation API (Backend) :** `http://localhost:8000/docs`.

### Lancer la collecte d'articles (Ingestion)
La base de donnÃ©es est vide au premier lancement. Pour dÃ©clencher le scraper et l'analyse par l'IA, exÃ©cutez le script d'ingestion directement dans le conteneur backend :

```bash
docker exec -it cyberwatch_backend python ingest.py
```
*Note : Le premier lancement peut prendre du temps car le conteneur doit tÃ©lÃ©charger le modÃ¨le franÃ§ais de spaCy et le modÃ¨le d'embeddings.*

---

## ğŸ“‚ Architecture du Projet

```text
CyberWatch/
â”œâ”€â”€ docker-compose.yml       # Orchestration des conteneurs
â”œâ”€â”€ backend/                 # API FastAPI & Logique d'ingestion
â”‚   â”œâ”€â”€ api.py               # Routes de l'API
â”‚   â”œâ”€â”€ ingest.py            # Script principal de scraping
â”‚   â”œâ”€â”€ rag.py               # Logique d'IA (LlamaIndex / Ollama)
â”‚   â”œâ”€â”€ scraper.py           # Logique d'extraction web
â”‚   â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile           # Configuration Docker du Backend
â””â”€â”€ frontend/                # Interface Utilisateur Nginx
    â”œâ”€â”€ index.html           # Structure de la page
    â”œâ”€â”€ app.js               # Logique dynamique et appels API
    â”œâ”€â”€ config.js            # Configuration de l'URL de l'API
    â”œâ”€â”€ style.css            # Styles personnalisÃ©s
    â””â”€â”€ Dockerfile           # Configuration Docker du Frontend
```